# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CI4pl1y4QsWUrnSYPK3NcS786sPQw2tf
"""

import re
import os
import pickle
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
from sklearn.preprocessing import normalize
from collections import defaultdict

MODEL_NAME = "indolem/indobert-base-uncased"
DATA_PATH = "/content/df (1).csv"
SAVE_DIR = "model"
os.makedirs(SAVE_DIR, exist_ok=True)

def minimal_preprocessing(text):
    """Membersihkan karakter khusus dan whitespace"""
    text = str(text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

print("ðŸ”¹ Loading dataset...")
df = pd.read_csv(DATA_PATH)
df["Pertanyaan_Clean"] = df["Pertanyaan"].apply(minimal_preprocessing)
df["Jawaban_Clean"] = df["Jawaban"].apply(minimal_preprocessing)
df = df.drop_duplicates(subset=["Pertanyaan_Clean"], keep="first")

print(f"Dataset loaded: {df.shape[0]} rows")

print(f"ðŸ”¹ Loading IndoBERT model: {MODEL_NAME}")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
bert_model = AutoModel.from_pretrained(MODEL_NAME)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)
bert_model.eval()

class KeywordNER:
    def __init__(self):
        # KAMUS KATA KUNCI YANG DIPERKAYA (Sesuai dengan kode kedua)
        self.mental_health_keywords = {
            'anxiety': [
                'cemas', 'gelisah', 'khawatir', 'panik', 'takut', 'nervous', 'anxiety',
                'deg-degan', 'jantung berdebar', 'keringat dingin', 'tegang',
                'was-was', 'overthinking', 'kecemasan', 'gangguan kecemasan'
            ],
            'depression': [
                'depresi', 'sedih', 'murung', 'putus asa', 'hopeless', 'down',
                'tidak bersemangat', 'malas', 'lelah', 'capek', 'kosong', 'hampa',
                'tidak ada motivasi', 'kehilangan minat', 'bad mood'
            ],
            'stress': [
                'stres', 'stress', 'tekanan', 'beban', 'pusing', 'overwhelmed',
                'kewalahan', 'terbebani', 'lelah mental', 'burnout', 'jenuh',
                'frustrasi', 'terpuruk', 'tertekan'
            ],
            'sleep_disorder': [
                'tidur', 'insomnia', 'susah tidur', 'tidak bisa tidur', 'begadang',
                'mimpi buruk', 'nightmare', 'bangun malam', 'gelisah tidur',
                'mengigau', 'sleepwalking', 'kantuk', 'ngantuk'
            ],
            'adhd': [
                'adhd', 'hiperaktif', 'hyperactive', 'sulit fokus', 'tidak bisa diam',
                'impulsif', 'pelupa', 'ceroboh', 'attention deficit', 'konsentrasi',
                'susah berkonsentrasi', 'mudah teralihkan'
            ],
            'autism': [
                'autis', 'autism', 'spektrum autisme', 'komunikasi sosial',
                'interaksi sosial', 'repetitif', 'stimming', 'sensori',
                'rutinitas', 'pola perilaku'
            ],
            'bipolar': [
                'bipolar', 'mood swing', 'mania', 'manik', 'euforia',
                'perubahan mood', 'naik turun', 'episode', 'hypomanic'
            ],
            'ptsd': [
                'trauma', 'ptsd', 'flashback', 'kenangan buruk', 'terganggu',
                'kekerasan', 'pelecehan', 'abuse', 'shock', 'terpukul'
            ],
            'eating_disorder': [
                'makan', 'nafsu makan', 'anoreksia', 'bulimia', 'binge eating',
                'diet berlebihan', 'tidak mau makan', 'muntah', 'body image'
            ],
            'addiction': [
                'kecanduan', 'adiksi', 'ketergantungan', 'narkoba', 'alkohol',
                'rokok', 'game online', 'media sosial', 'gambling', 'judi'
            ],
            'ocd': [
                'ocd', 'obsesi', 'kompulsi', 'ritual', 'berulang-ulang',
                'tidak bisa berhenti', 'terus menerus', 'terpaksa melakukan'
            ],
            'schizophrenia': [
                'skizofrenia', 'halusinasi', 'delusi', 'waham', 'mendengar suara',
                'melihat sesuatu', 'paranoid', 'curiga berlebihan'
            ]
        }
        self.demographic_keywords = {
            'child': ['anak', 'balita', 'bocah', 'kecil', 'sd', 'tk'],
            'teen': ['remaja', 'abg', 'smp', 'sma', 'teenager', 'adolescent'],
            'adult': ['dewasa', 'kuliah', 'kerja', 'karir', 'menikah'],
            'elderly': ['lansia', 'tua', 'lanjut usia', 'pensiunan'] # Tambahan elderly
        }
        self.severity_keywords = {
            'mild': ['ringan', 'sedikit', 'agak', 'kadang-kadang', 'sesekali'], # Diperkaya
            'moderate': ['sedang', 'cukup', 'lumayan', 'sering'], # Diperkaya
            'severe': ['parah', 'berat', 'sangat', 'ekstrem', 'selalu', 'terus menerus'] # Diperkaya
        }

    def extract_entities(self, text):
        text_lower = text.lower()
        # Struktur entities ini sudah konsisten
        entities = {'mental_health': [], 'demographic': [], 'severity': []}

        for cat, words in self.mental_health_keywords.items():
            entities['mental_health'] += [(cat, w) for w in words if w in text_lower]
        for cat, words in self.demographic_keywords.items():
            entities['demographic'] += [(cat, w) for w in words if w in text_lower]
        for cat, words in self.severity_keywords.items():
            entities['severity'] += [(cat, w) for w in words if w in text_lower]
        return entities

    def get_label_keywords(self, df):
        label_keywords = defaultdict(set)
        for label in df['Label'].unique():
            label_texts = df[df['Label'] == label]['Pertanyaan_Clean'].tolist()
            for text in label_texts:
                entities = self.extract_entities(text)
                # Pengumpulan kata kunci di sini sudah sesuai dengan kode kedua
                for cat, kw in entities['mental_health'] + entities['demographic'] + entities['severity']:
                    label_keywords[label].add(kw)
        return dict(label_keywords)

class IndoBERTFeatureExtractor:
    def __init__(self, model, tokenizer, device, max_length=256):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.max_length = max_length

    def extract_features(self, texts, batch_size=8):
        """Ekstraksi embedding [CLS] dari IndoBERT"""
        all_features = []
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            encoded = self.tokenizer(
                batch_texts,
                padding=True,
                truncation=True,
                max_length=self.max_length,
                return_tensors='pt'
            ).to(self.device)

            with torch.no_grad():
                outputs = self.model(**encoded)
                features = outputs.last_hidden_state[:, 0, :].cpu().numpy()
            all_features.append(features)

        features = np.vstack(all_features)
        # Normalisasi fitur BERT tetap dipertahankan
        return normalize(features)

print("ðŸ”¹ Initializing NER and extracting keywords...")
# PENGGUNAAN KLASIS BARU DENGAN KAMUS YANG DIPERKAYA
ner = KeywordNER()
label_keywords = ner.get_label_keywords(df)

print("ðŸ”¹ Extracting IndoBERT embeddings...")
extractor = IndoBERTFeatureExtractor(bert_model, tokenizer, device)
features = extractor.extract_features(df["Pertanyaan_Clean"].tolist())

save_path = os.path.join(SAVE_DIR, "preprocessed_components.pkl")
with open(save_path, "wb") as f:
    # DATA YANG DISIMPAN SUDAH KONSISTEN DENGAN KEBUTUHAN KLASIFIKASI
    pickle.dump({
        "questions": df["Pertanyaan_Clean"].tolist(),
        "answers": df["Jawaban_Clean"].tolist(),
        "labels": df["Label"].tolist() if "Label" in df.columns else None,
        "features": features,
        "label_keywords": label_keywords
    }, f)

print(f"âœ… Preprocessing selesai. File disimpan di: {save_path}")